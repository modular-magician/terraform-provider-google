// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file in
//     .github/CONTRIBUTING.md.
//
// ----------------------------------------------------------------------------

package google

import (
	"fmt"
	"log"
	"reflect"
	"strconv"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/helper/validation"
)

func resourceMLEngineJob() *schema.Resource {
	return &schema.Resource{
		Create: resourceMLEngineJobCreate,
		Read:   resourceMLEngineJobRead,
		Delete: resourceMLEngineJobDelete,

		Importer: &schema.ResourceImporter{
			State: resourceMLEngineJobImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(4 * time.Minute),
			Delete: schema.DefaultTimeout(4 * time.Minute),
		},

		Schema: map[string]*schema.Schema{
			"job_id": {
				Type:     schema.TypeString,
				Required: true,
				ForceNew: true,
			},
			"labels": {
				Type:     schema.TypeMap,
				Optional: true,
				ForceNew: true,
				Elem:     &schema.Schema{Type: schema.TypeString},
			},
			"training_input": {
				Type:     schema.TypeList,
				Optional: true,
				ForceNew: true,
				MaxItems: 1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"package_uris": {
							Type:     schema.TypeList,
							Required: true,
							ForceNew: true,
							Elem: &schema.Schema{
								Type: schema.TypeString,
							},
						},
						"python_module": {
							Type:     schema.TypeString,
							Required: true,
							ForceNew: true,
						},
						"region": {
							Type:     schema.TypeString,
							Required: true,
							ForceNew: true,
						},
						"scale_tier": {
							Type:         schema.TypeString,
							Required:     true,
							ForceNew:     true,
							ValidateFunc: validation.StringInSlice([]string{"BASIC", "STANDARD_1", "PREMIUM_1", "BASIC_GPU", "BASIC_TPU", "CUSTOM"}, false),
						},
						"args": {
							Type:     schema.TypeList,
							Optional: true,
							ForceNew: true,
							Elem: &schema.Schema{
								Type: schema.TypeString,
							},
						},
						"job_dir": {
							Type:     schema.TypeString,
							Optional: true,
							ForceNew: true,
						},
						"master_config": {
							Type:     schema.TypeList,
							Optional: true,
							ForceNew: true,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"accelerator_config": {
										Type:     schema.TypeList,
										Optional: true,
										ForceNew: true,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"count": {
													Type:     schema.TypeInt,
													Optional: true,
													ForceNew: true,
												},
												"type": {
													Type:         schema.TypeString,
													Optional:     true,
													ForceNew:     true,
													ValidateFunc: validation.StringInSlice([]string{"ACCELERATOR_TYPE_UNSPECIFIED", "NVIDIA_TESLA_K80", "NVIDIA_TESLA_P100", "NVIDIA_TESLA_V100", "NVIDIA_TESLA_P4", "NVIDIA_TESLA_T4", "TPU_V2", "TPU_V3", ""}, false),
												},
											},
										},
									},
									"image_uri": {
										Type:     schema.TypeString,
										Optional: true,
										ForceNew: true,
									},
									"tpu_tf_version": {
										Type:     schema.TypeString,
										Optional: true,
										ForceNew: true,
									},
								},
							},
						},
						"master_type": {
							Type:     schema.TypeString,
							Optional: true,
							ForceNew: true,
						},
						"parameter_server_config": {
							Type:     schema.TypeList,
							Optional: true,
							ForceNew: true,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"accelerator_config": {
										Type:     schema.TypeList,
										Optional: true,
										ForceNew: true,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"count": {
													Type:     schema.TypeInt,
													Optional: true,
													ForceNew: true,
												},
												"type": {
													Type:         schema.TypeString,
													Optional:     true,
													ForceNew:     true,
													ValidateFunc: validation.StringInSlice([]string{"ACCELERATOR_TYPE_UNSPECIFIED", "NVIDIA_TESLA_K80", "NVIDIA_TESLA_P100", "NVIDIA_TESLA_V100", "NVIDIA_TESLA_P4", "NVIDIA_TESLA_T4", "TPU_V2", "TPU_V3", ""}, false),
												},
											},
										},
									},
									"image_uri": {
										Type:     schema.TypeString,
										Optional: true,
										ForceNew: true,
									},
									"tpu_tf_version": {
										Type:     schema.TypeString,
										Optional: true,
										ForceNew: true,
									},
								},
							},
						},
						"parameter_server_count": {
							Type:     schema.TypeInt,
							Optional: true,
							ForceNew: true,
						},
						"parameter_server_type": {
							Type:     schema.TypeString,
							Optional: true,
							ForceNew: true,
						},
						"python_version": {
							Type:     schema.TypeString,
							Optional: true,
							ForceNew: true,
						},
						"runtime_version": {
							Type:     schema.TypeString,
							Optional: true,
							ForceNew: true,
						},
						"worker_config": {
							Type:     schema.TypeList,
							Optional: true,
							ForceNew: true,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"accelerator_config": {
										Type:     schema.TypeList,
										Optional: true,
										ForceNew: true,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"count": {
													Type:     schema.TypeInt,
													Optional: true,
													ForceNew: true,
												},
												"type": {
													Type:         schema.TypeString,
													Optional:     true,
													ForceNew:     true,
													ValidateFunc: validation.StringInSlice([]string{"ACCELERATOR_TYPE_UNSPECIFIED", "NVIDIA_TESLA_K80", "NVIDIA_TESLA_P100", "NVIDIA_TESLA_V100", "NVIDIA_TESLA_P4", "NVIDIA_TESLA_T4", "TPU_V2", "TPU_V3", ""}, false),
												},
											},
										},
									},
									"image_uri": {
										Type:     schema.TypeString,
										Optional: true,
										ForceNew: true,
									},
									"tpu_tf_version": {
										Type:     schema.TypeString,
										Optional: true,
										ForceNew: true,
									},
								},
							},
						},
						"worker_count": {
							Type:     schema.TypeInt,
							Optional: true,
							ForceNew: true,
						},
						"worker_type": {
							Type:     schema.TypeString,
							Optional: true,
							ForceNew: true,
						},
					},
				},
			},
			"create_time": {
				Type:     schema.TypeString,
				Computed: true,
			},
			"end_time": {
				Type:     schema.TypeString,
				Computed: true,
			},
			"error_message": {
				Type:     schema.TypeString,
				Computed: true,
			},
			"state": {
				Type:     schema.TypeString,
				Computed: true,
			},
			"training_output": {
				Type:     schema.TypeList,
				Computed: true,
				MaxItems: 1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"built_in_algorithm_output": {
							Type:     schema.TypeList,
							Optional: true,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"framework": {
										Type:     schema.TypeString,
										Optional: true,
									},
									"model_path": {
										Type:     schema.TypeInt,
										Optional: true,
									},
									"python_version": {
										Type:     schema.TypeInt,
										Optional: true,
									},
									"runtime_version": {
										Type:     schema.TypeInt,
										Optional: true,
									},
								},
							},
						},
						"completed_trial_count": {
							Type:     schema.TypeString,
							Optional: true,
						},
						"consumed_ml_units": {
							Type:     schema.TypeInt,
							Optional: true,
						},
						"hyperparameter_metric_tag": {
							Type:     schema.TypeString,
							Optional: true,
						},
						"is_built_in_algorithm_job": {
							Type:     schema.TypeString,
							Optional: true,
						},
						"is_hyperparameter_tuning_job": {
							Type:     schema.TypeBool,
							Optional: true,
						},
						"trials": {
							Type:     schema.TypeList,
							Optional: true,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"all_metrics": {
										Type:     schema.TypeList,
										Optional: true,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"objective_value": {
													Type:     schema.TypeInt,
													Optional: true,
												},
												"training_step": {
													Type:     schema.TypeString,
													Optional: true,
												},
											},
										},
									},
									"built_in_algorithm_output": {
										Type:     schema.TypeList,
										Optional: true,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"framework": {
													Type:     schema.TypeString,
													Optional: true,
												},
												"model_path": {
													Type:     schema.TypeInt,
													Optional: true,
												},
												"python_version": {
													Type:     schema.TypeInt,
													Optional: true,
												},
												"runtime_version": {
													Type:     schema.TypeInt,
													Optional: true,
												},
											},
										},
									},
									"final_metric": {
										Type:     schema.TypeList,
										Optional: true,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"objective_value": {
													Type:     schema.TypeInt,
													Optional: true,
												},
												"training_step": {
													Type:     schema.TypeString,
													Optional: true,
												},
											},
										},
									},
									"hyperparameters": {
										Type:     schema.TypeMap,
										Optional: true,
										Elem:     &schema.Schema{Type: schema.TypeString},
									},
									"is_trial_stopped_early": {
										Type:     schema.TypeBool,
										Optional: true,
									},
									"trial_id": {
										Type:     schema.TypeString,
										Optional: true,
									},
									"end_time": {
										Type:     schema.TypeString,
										Computed: true,
									},
									"start_time": {
										Type:     schema.TypeString,
										Computed: true,
									},
									"state": {
										Type:     schema.TypeString,
										Computed: true,
									},
								},
							},
						},
					},
				},
			},
			"project": {
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
				ForceNew: true,
			},
		},
	}
}

func resourceMLEngineJobCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*Config)

	obj := make(map[string]interface{})
	jobIdProp, err := expandMLEngineJobJobId(d.Get("job_id"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("job_id"); !isEmptyValue(reflect.ValueOf(jobIdProp)) && (ok || !reflect.DeepEqual(v, jobIdProp)) {
		obj["jobId"] = jobIdProp
	}
	labelsProp, err := expandMLEngineJobLabels(d.Get("labels"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("labels"); !isEmptyValue(reflect.ValueOf(labelsProp)) && (ok || !reflect.DeepEqual(v, labelsProp)) {
		obj["labels"] = labelsProp
	}
	trainingInputProp, err := expandMLEngineJobTrainingInput(d.Get("training_input"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("training_input"); !isEmptyValue(reflect.ValueOf(trainingInputProp)) && (ok || !reflect.DeepEqual(v, trainingInputProp)) {
		obj["trainingInput"] = trainingInputProp
	}

	url, err := replaceVars(d, config, "{{MLEngineBasePath}}projects/{{project}}/jobs")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Creating new Job: %#v", obj)
	project, err := getProject(d, config)
	if err != nil {
		return err
	}
	res, err := sendRequestWithTimeout(config, "POST", project, url, obj, d.Timeout(schema.TimeoutCreate))
	if err != nil {
		return fmt.Errorf("Error creating Job: %s", err)
	}

	// Store the ID now
	id, err := replaceVars(d, config, "{{name}}")
	if err != nil {
		return fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	log.Printf("[DEBUG] Finished creating Job %q: %#v", d.Id(), res)

	return resourceMLEngineJobRead(d, meta)
}

func resourceMLEngineJobRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*Config)

	url, err := replaceVars(d, config, "{{MLEngineBasePath}}projects/{{project}}/jobs/{{name}}")
	if err != nil {
		return err
	}

	project, err := getProject(d, config)
	if err != nil {
		return err
	}
	res, err := sendRequest(config, "GET", project, url, nil)
	if err != nil {
		return handleNotFoundError(err, d, fmt.Sprintf("MLEngineJob %q", d.Id()))
	}

	if err := d.Set("project", project); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}

	if err := d.Set("job_id", flattenMLEngineJobJobId(res["jobId"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("create_time", flattenMLEngineJobCreateTime(res["createTime"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("end_time", flattenMLEngineJobEndTime(res["endTime"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("state", flattenMLEngineJobState(res["state"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("error_message", flattenMLEngineJobErrorMessage(res["errorMessage"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("labels", flattenMLEngineJobLabels(res["labels"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("training_input", flattenMLEngineJobTrainingInput(res["trainingInput"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("training_output", flattenMLEngineJobTrainingOutput(res["trainingOutput"], d)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}

	return nil
}

func resourceMLEngineJobDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*Config)

	project, err := getProject(d, config)
	if err != nil {
		return err
	}

	url, err := replaceVars(d, config, "{{MLEngineBasePath}}projects/{{project}}/jobs/{{name}}")
	if err != nil {
		return err
	}

	var obj map[string]interface{}
	log.Printf("[DEBUG] Deleting Job %q", d.Id())

	res, err := sendRequestWithTimeout(config, "DELETE", project, url, obj, d.Timeout(schema.TimeoutDelete))
	if err != nil {
		return handleNotFoundError(err, d, "Job")
	}

	log.Printf("[DEBUG] Finished deleting Job %q: %#v", d.Id(), res)
	return nil
}

func resourceMLEngineJobImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	config := meta.(*Config)
	if err := parseImportId([]string{
		"projects/(?P<project>[^/]+)/jobs/(?P<name>[^/]+)",
		"(?P<project>[^/]+)/(?P<name>[^/]+)",
		"(?P<name>[^/]+)",
	}, d, config); err != nil {
		return nil, err
	}

	// Replace import id for the resource id
	id, err := replaceVars(d, config, "{{name}}")
	if err != nil {
		return nil, fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	return []*schema.ResourceData{d}, nil
}

func flattenMLEngineJobJobId(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobCreateTime(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobEndTime(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobState(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobErrorMessage(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobLabels(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInput(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["scale_tier"] =
		flattenMLEngineJobTrainingInputScaleTier(original["scaleTier"], d)
	transformed["master_type"] =
		flattenMLEngineJobTrainingInputMasterType(original["masterType"], d)
	transformed["master_config"] =
		flattenMLEngineJobTrainingInputMasterConfig(original["masterConfig"], d)
	transformed["worker_type"] =
		flattenMLEngineJobTrainingInputWorkerType(original["workerType"], d)
	transformed["worker_config"] =
		flattenMLEngineJobTrainingInputWorkerConfig(original["workerConfig"], d)
	transformed["parameter_server_type"] =
		flattenMLEngineJobTrainingInputParameterServerType(original["parameterServerType"], d)
	transformed["parameter_server_config"] =
		flattenMLEngineJobTrainingInputParameterServerConfig(original["parameterServerConfig"], d)
	transformed["worker_count"] =
		flattenMLEngineJobTrainingInputWorkerCount(original["workerCount"], d)
	transformed["parameter_server_count"] =
		flattenMLEngineJobTrainingInputParameterServerCount(original["parameterServerCount"], d)
	transformed["package_uris"] =
		flattenMLEngineJobTrainingInputPackageUris(original["packageUris"], d)
	transformed["python_module"] =
		flattenMLEngineJobTrainingInputPythonModule(original["pythonModule"], d)
	transformed["args"] =
		flattenMLEngineJobTrainingInputArgs(original["args"], d)
	transformed["region"] =
		flattenMLEngineJobTrainingInputRegion(original["region"], d)
	transformed["job_dir"] =
		flattenMLEngineJobTrainingInputJobDir(original["jobDir"], d)
	transformed["runtime_version"] =
		flattenMLEngineJobTrainingInputRuntimeVersion(original["runtimeVersion"], d)
	transformed["python_version"] =
		flattenMLEngineJobTrainingInputPythonVersion(original["pythonVersion"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingInputScaleTier(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputMasterType(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputMasterConfig(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["accelerator_config"] =
		flattenMLEngineJobTrainingInputMasterConfigAcceleratorConfig(original["acceleratorConfig"], d)
	transformed["image_uri"] =
		flattenMLEngineJobTrainingInputMasterConfigImageUri(original["imageUri"], d)
	transformed["tpu_tf_version"] =
		flattenMLEngineJobTrainingInputMasterConfigTPUTfVersion(original["tpuTfVersion"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingInputMasterConfigAcceleratorConfig(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["count"] =
		flattenMLEngineJobTrainingInputMasterConfigAcceleratorConfigCount(original["count"], d)
	transformed["type"] =
		flattenMLEngineJobTrainingInputMasterConfigAcceleratorConfigType(original["type"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingInputMasterConfigAcceleratorConfigCount(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingInputMasterConfigAcceleratorConfigType(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputMasterConfigImageUri(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputMasterConfigTPUTfVersion(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputWorkerType(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputWorkerConfig(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["accelerator_config"] =
		flattenMLEngineJobTrainingInputWorkerConfigAcceleratorConfig(original["acceleratorConfig"], d)
	transformed["image_uri"] =
		flattenMLEngineJobTrainingInputWorkerConfigImageUri(original["imageUri"], d)
	transformed["tpu_tf_version"] =
		flattenMLEngineJobTrainingInputWorkerConfigTPUTfVersion(original["tpuTfVersion"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingInputWorkerConfigAcceleratorConfig(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["count"] =
		flattenMLEngineJobTrainingInputWorkerConfigAcceleratorConfigCount(original["count"], d)
	transformed["type"] =
		flattenMLEngineJobTrainingInputWorkerConfigAcceleratorConfigType(original["type"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingInputWorkerConfigAcceleratorConfigCount(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingInputWorkerConfigAcceleratorConfigType(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputWorkerConfigImageUri(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputWorkerConfigTPUTfVersion(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputParameterServerType(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputParameterServerConfig(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["accelerator_config"] =
		flattenMLEngineJobTrainingInputParameterServerConfigAcceleratorConfig(original["acceleratorConfig"], d)
	transformed["image_uri"] =
		flattenMLEngineJobTrainingInputParameterServerConfigImageUri(original["imageUri"], d)
	transformed["tpu_tf_version"] =
		flattenMLEngineJobTrainingInputParameterServerConfigTPUTfVersion(original["tpuTfVersion"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingInputParameterServerConfigAcceleratorConfig(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["count"] =
		flattenMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigCount(original["count"], d)
	transformed["type"] =
		flattenMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigType(original["type"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigCount(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigType(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputParameterServerConfigImageUri(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputParameterServerConfigTPUTfVersion(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputWorkerCount(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingInputParameterServerCount(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingInputPackageUris(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputPythonModule(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputArgs(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputRegion(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputJobDir(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputRuntimeVersion(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingInputPythonVersion(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutput(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["completed_trial_count"] =
		flattenMLEngineJobTrainingOutputCompletedTrialCount(original["completedTrialCount"], d)
	transformed["trials"] =
		flattenMLEngineJobTrainingOutputTrials(original["trials"], d)
	transformed["consumed_ml_units"] =
		flattenMLEngineJobTrainingOutputConsumedMLUnits(original["consumedMLUnits"], d)
	transformed["is_hyperparameter_tuning_job"] =
		flattenMLEngineJobTrainingOutputIsHyperparameterTuningJob(original["isHyperparameterTuningJob"], d)
	transformed["is_built_in_algorithm_job"] =
		flattenMLEngineJobTrainingOutputIsBuiltInAlgorithmJob(original["isBuiltInAlgorithmJob"], d)
	transformed["built_in_algorithm_output"] =
		flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutput(original["builtInAlgorithmOutput"], d)
	transformed["hyperparameter_metric_tag"] =
		flattenMLEngineJobTrainingOutputHyperparameterMetricTag(original["hyperparameterMetricTag"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingOutputCompletedTrialCount(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrials(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["trial_id"] =
		flattenMLEngineJobTrainingOutputTrialsTrialId(original["trialId"], d)
	transformed["hyperparameters"] =
		flattenMLEngineJobTrainingOutputTrialsHyperparameters(original["hyperparameters"], d)
	transformed["start_time"] =
		flattenMLEngineJobTrainingOutputTrialsStartTime(original["startTime"], d)
	transformed["end_time"] =
		flattenMLEngineJobTrainingOutputTrialsEndTime(original["endTime"], d)
	transformed["state"] =
		flattenMLEngineJobTrainingOutputTrialsState(original["state"], d)
	transformed["final_metric"] =
		flattenMLEngineJobTrainingOutputTrialsFinalMetric(original["finalMetric"], d)
	transformed["is_trial_stopped_early"] =
		flattenMLEngineJobTrainingOutputTrialsIsTrialStoppedEarly(original["isTrialStoppedEarly"], d)
	transformed["all_metrics"] =
		flattenMLEngineJobTrainingOutputTrialsAllMetrics(original["allMetrics"], d)
	transformed["built_in_algorithm_output"] =
		flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutput(original["builtInAlgorithmOutput"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingOutputTrialsTrialId(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsHyperparameters(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsStartTime(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsEndTime(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsState(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsFinalMetric(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["training_step"] =
		flattenMLEngineJobTrainingOutputTrialsFinalMetricTrainingStep(original["trainingStep"], d)
	transformed["objective_value"] =
		flattenMLEngineJobTrainingOutputTrialsFinalMetricObjectiveValue(original["objectiveValue"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingOutputTrialsFinalMetricTrainingStep(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsFinalMetricObjectiveValue(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputTrialsIsTrialStoppedEarly(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsAllMetrics(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["training_step"] =
		flattenMLEngineJobTrainingOutputTrialsAllMetricsTrainingStep(original["trainingStep"], d)
	transformed["objective_value"] =
		flattenMLEngineJobTrainingOutputTrialsAllMetricsObjectiveValue(original["objectiveValue"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingOutputTrialsAllMetricsTrainingStep(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsAllMetricsObjectiveValue(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutput(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["framework"] =
		flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputFramework(original["framework"], d)
	transformed["runtime_version"] =
		flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputRuntimeVersion(original["runtimeVersion"], d)
	transformed["python_version"] =
		flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputPythonVersion(original["pythonVersion"], d)
	transformed["model_path"] =
		flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputModelPath(original["modelPath"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputFramework(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputRuntimeVersion(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputPythonVersion(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputTrialsBuiltInAlgorithmOutputModelPath(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputConsumedMLUnits(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputIsHyperparameterTuningJob(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputIsBuiltInAlgorithmJob(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutput(v interface{}, d *schema.ResourceData) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["framework"] =
		flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputFramework(original["framework"], d)
	transformed["runtime_version"] =
		flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputRuntimeVersion(original["runtimeVersion"], d)
	transformed["python_version"] =
		flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputPythonVersion(original["pythonVersion"], d)
	transformed["model_path"] =
		flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputModelPath(original["modelPath"], d)
	return []interface{}{transformed}
}
func flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputFramework(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputRuntimeVersion(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputPythonVersion(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputBuiltInAlgorithmOutputModelPath(v interface{}, d *schema.ResourceData) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := strconv.ParseInt(strVal, 10, 64); err == nil {
			return intVal
		} // let terraform core handle it if we can't convert the string to an int.
	}
	return v
}

func flattenMLEngineJobTrainingOutputHyperparameterMetricTag(v interface{}, d *schema.ResourceData) interface{} {
	return v
}

func expandMLEngineJobJobId(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	var jobname string
	var timestmp string
	t := time.Now()
	timestmp = t.Format("20060102_150405")
	jobname = v.(string) + "_" + timestmp
	return jobname, nil
}

func expandMLEngineJobLabels(v interface{}, d TerraformResourceData, config *Config) (map[string]string, error) {
	if v == nil {
		return map[string]string{}, nil
	}
	m := make(map[string]string)
	for k, val := range v.(map[string]interface{}) {
		m[k] = val.(string)
	}
	return m, nil
}

func expandMLEngineJobTrainingInput(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedScaleTier, err := expandMLEngineJobTrainingInputScaleTier(original["scale_tier"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedScaleTier); val.IsValid() && !isEmptyValue(val) {
		transformed["scaleTier"] = transformedScaleTier
	}

	transformedMasterType, err := expandMLEngineJobTrainingInputMasterType(original["master_type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMasterType); val.IsValid() && !isEmptyValue(val) {
		transformed["masterType"] = transformedMasterType
	}

	transformedMasterConfig, err := expandMLEngineJobTrainingInputMasterConfig(original["master_config"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMasterConfig); val.IsValid() && !isEmptyValue(val) {
		transformed["masterConfig"] = transformedMasterConfig
	}

	transformedWorkerType, err := expandMLEngineJobTrainingInputWorkerType(original["worker_type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedWorkerType); val.IsValid() && !isEmptyValue(val) {
		transformed["workerType"] = transformedWorkerType
	}

	transformedWorkerConfig, err := expandMLEngineJobTrainingInputWorkerConfig(original["worker_config"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedWorkerConfig); val.IsValid() && !isEmptyValue(val) {
		transformed["workerConfig"] = transformedWorkerConfig
	}

	transformedParameterServerType, err := expandMLEngineJobTrainingInputParameterServerType(original["parameter_server_type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParameterServerType); val.IsValid() && !isEmptyValue(val) {
		transformed["parameterServerType"] = transformedParameterServerType
	}

	transformedParameterServerConfig, err := expandMLEngineJobTrainingInputParameterServerConfig(original["parameter_server_config"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParameterServerConfig); val.IsValid() && !isEmptyValue(val) {
		transformed["parameterServerConfig"] = transformedParameterServerConfig
	}

	transformedWorkerCount, err := expandMLEngineJobTrainingInputWorkerCount(original["worker_count"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedWorkerCount); val.IsValid() && !isEmptyValue(val) {
		transformed["workerCount"] = transformedWorkerCount
	}

	transformedParameterServerCount, err := expandMLEngineJobTrainingInputParameterServerCount(original["parameter_server_count"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParameterServerCount); val.IsValid() && !isEmptyValue(val) {
		transformed["parameterServerCount"] = transformedParameterServerCount
	}

	transformedPackageUris, err := expandMLEngineJobTrainingInputPackageUris(original["package_uris"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedPackageUris); val.IsValid() && !isEmptyValue(val) {
		transformed["packageUris"] = transformedPackageUris
	}

	transformedPythonModule, err := expandMLEngineJobTrainingInputPythonModule(original["python_module"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedPythonModule); val.IsValid() && !isEmptyValue(val) {
		transformed["pythonModule"] = transformedPythonModule
	}

	transformedArgs, err := expandMLEngineJobTrainingInputArgs(original["args"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedArgs); val.IsValid() && !isEmptyValue(val) {
		transformed["args"] = transformedArgs
	}

	transformedRegion, err := expandMLEngineJobTrainingInputRegion(original["region"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRegion); val.IsValid() && !isEmptyValue(val) {
		transformed["region"] = transformedRegion
	}

	transformedJobDir, err := expandMLEngineJobTrainingInputJobDir(original["job_dir"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedJobDir); val.IsValid() && !isEmptyValue(val) {
		transformed["jobDir"] = transformedJobDir
	}

	transformedRuntimeVersion, err := expandMLEngineJobTrainingInputRuntimeVersion(original["runtime_version"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRuntimeVersion); val.IsValid() && !isEmptyValue(val) {
		transformed["runtimeVersion"] = transformedRuntimeVersion
	}

	transformedPythonVersion, err := expandMLEngineJobTrainingInputPythonVersion(original["python_version"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedPythonVersion); val.IsValid() && !isEmptyValue(val) {
		transformed["pythonVersion"] = transformedPythonVersion
	}

	return transformed, nil
}

func expandMLEngineJobTrainingInputScaleTier(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputMasterType(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputMasterConfig(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedAcceleratorConfig, err := expandMLEngineJobTrainingInputMasterConfigAcceleratorConfig(original["accelerator_config"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedAcceleratorConfig); val.IsValid() && !isEmptyValue(val) {
		transformed["acceleratorConfig"] = transformedAcceleratorConfig
	}

	transformedImageUri, err := expandMLEngineJobTrainingInputMasterConfigImageUri(original["image_uri"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedImageUri); val.IsValid() && !isEmptyValue(val) {
		transformed["imageUri"] = transformedImageUri
	}

	transformedTPUTfVersion, err := expandMLEngineJobTrainingInputMasterConfigTPUTfVersion(original["tpu_tf_version"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTPUTfVersion); val.IsValid() && !isEmptyValue(val) {
		transformed["tpuTfVersion"] = transformedTPUTfVersion
	}

	return transformed, nil
}

func expandMLEngineJobTrainingInputMasterConfigAcceleratorConfig(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedCount, err := expandMLEngineJobTrainingInputMasterConfigAcceleratorConfigCount(original["count"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedCount); val.IsValid() && !isEmptyValue(val) {
		transformed["count"] = transformedCount
	}

	transformedType, err := expandMLEngineJobTrainingInputMasterConfigAcceleratorConfigType(original["type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedType); val.IsValid() && !isEmptyValue(val) {
		transformed["type"] = transformedType
	}

	return transformed, nil
}

func expandMLEngineJobTrainingInputMasterConfigAcceleratorConfigCount(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputMasterConfigAcceleratorConfigType(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputMasterConfigImageUri(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputMasterConfigTPUTfVersion(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputWorkerType(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputWorkerConfig(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedAcceleratorConfig, err := expandMLEngineJobTrainingInputWorkerConfigAcceleratorConfig(original["accelerator_config"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedAcceleratorConfig); val.IsValid() && !isEmptyValue(val) {
		transformed["acceleratorConfig"] = transformedAcceleratorConfig
	}

	transformedImageUri, err := expandMLEngineJobTrainingInputWorkerConfigImageUri(original["image_uri"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedImageUri); val.IsValid() && !isEmptyValue(val) {
		transformed["imageUri"] = transformedImageUri
	}

	transformedTPUTfVersion, err := expandMLEngineJobTrainingInputWorkerConfigTPUTfVersion(original["tpu_tf_version"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTPUTfVersion); val.IsValid() && !isEmptyValue(val) {
		transformed["tpuTfVersion"] = transformedTPUTfVersion
	}

	return transformed, nil
}

func expandMLEngineJobTrainingInputWorkerConfigAcceleratorConfig(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedCount, err := expandMLEngineJobTrainingInputWorkerConfigAcceleratorConfigCount(original["count"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedCount); val.IsValid() && !isEmptyValue(val) {
		transformed["count"] = transformedCount
	}

	transformedType, err := expandMLEngineJobTrainingInputWorkerConfigAcceleratorConfigType(original["type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedType); val.IsValid() && !isEmptyValue(val) {
		transformed["type"] = transformedType
	}

	return transformed, nil
}

func expandMLEngineJobTrainingInputWorkerConfigAcceleratorConfigCount(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputWorkerConfigAcceleratorConfigType(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputWorkerConfigImageUri(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputWorkerConfigTPUTfVersion(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputParameterServerType(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputParameterServerConfig(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedAcceleratorConfig, err := expandMLEngineJobTrainingInputParameterServerConfigAcceleratorConfig(original["accelerator_config"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedAcceleratorConfig); val.IsValid() && !isEmptyValue(val) {
		transformed["acceleratorConfig"] = transformedAcceleratorConfig
	}

	transformedImageUri, err := expandMLEngineJobTrainingInputParameterServerConfigImageUri(original["image_uri"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedImageUri); val.IsValid() && !isEmptyValue(val) {
		transformed["imageUri"] = transformedImageUri
	}

	transformedTPUTfVersion, err := expandMLEngineJobTrainingInputParameterServerConfigTPUTfVersion(original["tpu_tf_version"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTPUTfVersion); val.IsValid() && !isEmptyValue(val) {
		transformed["tpuTfVersion"] = transformedTPUTfVersion
	}

	return transformed, nil
}

func expandMLEngineJobTrainingInputParameterServerConfigAcceleratorConfig(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedCount, err := expandMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigCount(original["count"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedCount); val.IsValid() && !isEmptyValue(val) {
		transformed["count"] = transformedCount
	}

	transformedType, err := expandMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigType(original["type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedType); val.IsValid() && !isEmptyValue(val) {
		transformed["type"] = transformedType
	}

	return transformed, nil
}

func expandMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigCount(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputParameterServerConfigAcceleratorConfigType(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputParameterServerConfigImageUri(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputParameterServerConfigTPUTfVersion(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputWorkerCount(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputParameterServerCount(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputPackageUris(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputPythonModule(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputArgs(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputRegion(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputJobDir(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputRuntimeVersion(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}

func expandMLEngineJobTrainingInputPythonVersion(v interface{}, d TerraformResourceData, config *Config) (interface{}, error) {
	return v, nil
}
